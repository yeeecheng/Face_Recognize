{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "from retinaface import RetinaFace\n",
    "from deepface import DeepFace\n",
    "from deepface.basemodels import Facenet\n",
    "from deepface.commons import functions, realtime, distance as dst\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User face detect\n",
    "class FaceDetect:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.detector = RetinaFace\n",
    "\n",
    "\n",
    "    def detect(self,frame):\n",
    "\n",
    "        img = frame.copy()\n",
    "        face_detect_result  = self.detector.detect_faces(img)\n",
    "        \n",
    "        if len(face_detect_result) == 0 :\n",
    "            return frame , False\n",
    "        for face in face_detect_result:\n",
    "            ROI = face_detect_result[face]['facial_area'] #min_x , min_y , max_x ,max_y\n",
    "            cv2.rectangle(frame,(ROI[0],ROI[1]),(ROI[2],ROI[3]),(0,255,0),2)\n",
    "\n",
    "        return frame , True \n",
    "\n",
    "    def pre_processing(self,frame):\n",
    "\n",
    "        processed_img = self.detector.extract_faces(frame)\n",
    "        \n",
    "        if len(processed_img) != 1:\n",
    "            return None , False\n",
    "        \n",
    "        frame = cv2.cvtColor(processed_img[0],cv2.COLOR_RGB2BGR) \n",
    "        return frame , True\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceRecognize:\n",
    "    \n",
    "    def __init__(self,model_name = \"Facenet\" , detector_backend = \"retinaface\" ,distance_metric =\"cosine\"):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.model = DeepFace.build_model(model_name)\n",
    "        self.detector_backend = detector_backend\n",
    "        self.distance_metric = distance_metric\n",
    "    \n",
    "    \n",
    "    def generate_representation(self , db_path):\n",
    "        \n",
    "        employees =  []\n",
    "        for r , d, f in os.walk(db_path):\n",
    "\n",
    "            for file in f:\n",
    "                \n",
    "                if ('.jpg' in file.lower()) or ('.png' in file.lower()):\n",
    "                    exact_path = r +\"/\" + file\n",
    "                    employees.append(exact_path)\n",
    "        if len(employees) == 0 :\n",
    "            raise ValueError(\"There is no image !\")\n",
    "        \n",
    "        representations = []\n",
    "\n",
    "        progress_bar = tqdm(range(0,len(employees)),desc=\"Calculating\")\n",
    "\n",
    "        for index in progress_bar:\n",
    "\n",
    "            employee = employees[index]\n",
    "            instance = []\n",
    "            instance.append(employee)\n",
    "\n",
    "            representation = DeepFace.represent(\n",
    "                img_path = employee,\n",
    "                model_name =self.model_name,\n",
    "                model = self.model,\n",
    "                enforce_detection=False,\n",
    "                detector_backend=self.detector_backend,\n",
    "                align = True,\n",
    "                normalization='base'\n",
    "            )\n",
    "            instance.append(representation)\n",
    "\n",
    "            representations.append(instance)\n",
    "\n",
    "        shutil.rmtree(db_path)\n",
    "        return representations\n",
    "        \n",
    "\n",
    "    def generate_file(self,representations,has_file=False):\n",
    "        \n",
    "        file_name = \"representation_%s.pkl\" % (self.model_name)\n",
    "        if has_file:\n",
    "            with open(f\"./{file_name}\",'rb') as f :\n",
    "                org_representations = pickle.load(f)\n",
    "            \n",
    "            for i  in representations:\n",
    "                org_representations.append(i)\n",
    "\n",
    "            representations = org_representations\n",
    "\n",
    "        with open(f\"./{file_name}\",'wb') as f :\n",
    "            pickle.dump(representations,f)\n",
    "\n",
    "    def recognize(self,img_path):\n",
    "        \n",
    "        file_name = \"representation_%s.pkl\" % (self.model_name)\n",
    "\n",
    "        with open(f\"{file_name}\",'rb') as f:\n",
    "            representations = pickle.load(f)\n",
    "    \n",
    "        df = pd.DataFrame(representations , columns = [\"identity\",\"%s_representation\" % (self.model_name)])\n",
    "    \n",
    "        progress_bar = tqdm(range(0,1),desc=\"Analyzing\")\n",
    "\n",
    "        for i in progress_bar:\n",
    "            \n",
    "\n",
    "            target_representation = DeepFace.represent(\n",
    "                img_path = img_path,\n",
    "                model_name =self.model_name,\n",
    "                model = self.model,\n",
    "                enforce_detection=False,\n",
    "                detector_backend=self.detector_backend,\n",
    "                align = True,\n",
    "                normalization='base'\n",
    "            )\n",
    "            \n",
    "\n",
    "            distances = []\n",
    "            for index ,instance in df.iterrows():\n",
    "                source_representation = instance[\"%s_representation\" % (self.model_name)]\n",
    "                \n",
    "                if self.distance_metric == \"cosine\":\n",
    "                    distance = dst.findCosineDistance(source_representation,target_representation)\n",
    "                elif self.distance_metric == \"euclidean\":\n",
    "                    distance = dst.findEuclideanDistance(source_representation,target_representation)\n",
    "                elif self.distance_metric == \"euclidean_12\":\n",
    "                    distance = dst.findEuclideanDistance(dst.l2_normalize(source_representation), dst.l2_normalize(target_representation))\n",
    "                \n",
    "                distances.append(distance)\n",
    "            \n",
    "            df[\"%s_%s\" % (self.model_name,self.distance_metric)] = distances\n",
    "            # find the accept range\n",
    "            threshold = dst.findThreshold(self.model_name,self.distance_metric)\n",
    "            # drop feature\n",
    "            df = df.drop(columns= [\"%s_representation\" % (self.model_name)])\n",
    "            # filter smaller and equal threshold\n",
    "            df = df[df[\"%s_%s\" % (self.model_name,self.distance_metric)] <= threshold]\n",
    "            # sort from small to large \n",
    "            df = df.sort_values(by = [\"%s_%s\" %(self.model_name,self.distance_metric)],ascending =True).reset_index(drop=True)\n",
    "\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            return \"Other\"\n",
    "        \n",
    "        else :\n",
    "            identity = df['identity'][0].split('/')[1].split('_')\n",
    "            return identity[0]+\" \"+identity[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_user(label):\n",
    "\n",
    "    face_detection = FaceDetect()\n",
    "    face_recognition = FaceRecognize()\n",
    "\n",
    "    # need num of user's data  \n",
    "    get_picture_num = 10\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        exit()\n",
    "\n",
    "    # create user dir \n",
    "    path = \"dataset\" \n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    with open(\"label.txt\",\"a+\") as f:\n",
    "        \n",
    "        f.write(\"user %s\\n\" %(label))\n",
    "\n",
    "    # cnt img_number \n",
    "    img_number = 0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        ret , frame  = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Cannot receive frame\")\n",
    "            break\n",
    "        \n",
    "        # pre-processing the img to only face \n",
    "        frame , check  = face_detection.pre_processing(frame)\n",
    "        \n",
    "        # haven't detect face ,skip\n",
    "        if not check :\n",
    "            continue\n",
    "        \n",
    "        # show \n",
    "        cv2.imshow(\"frame\",frame)\n",
    "        if cv2.waitKey(100) & 0xff ==ord('q'):\n",
    "            break\n",
    "        \n",
    "        # save img \n",
    "        cv2.imwrite(f\"{path}/user_{label}_{img_number}.jpg\",frame)\n",
    "        img_number+=1\n",
    "        \n",
    "        if img_number >= get_picture_num:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    representations = face_recognition.generate_representation(path)\n",
    "\n",
    "    has_file = os.path.isfile(\"representation_Facenet.pkl\")\n",
    "    face_recognition.generate_file( representations ,has_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recognize_user():\n",
    "\n",
    "    face_Detector = FaceDetect()\n",
    "    face_recognize =FaceRecognize()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        exit()\n",
    "    while True :\n",
    "        \n",
    "        ret , frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Cannot receive frame\")\n",
    "            break\n",
    "        \n",
    "        frame , check = face_Detector.pre_processing(frame)\n",
    "        if not check:\n",
    "            print(\"There is no face\")\n",
    "            continue\n",
    "        \n",
    "        cv2.imwrite(\"./detect.jpg\" , frame)\n",
    "        result = face_recognize.recognize(r\"./detect.jpg\")\n",
    "        print(\"detect %s\" % (result))\n",
    "        \n",
    "        if cv2.waitKey(100) & 0xff ==ord('q'):\n",
    "            break\n",
    "        \n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating: 100%|██████████| 10/10 [00:16<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main(MODE = \"Register\"):\n",
    "    \n",
    "    if MODE == \"Register\":\n",
    "        \n",
    "        register_user(\"2\")\n",
    "\n",
    "    elif MODE == \"Recognize\":\n",
    "        \n",
    "        recognize_user()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# check the representation size\n",
    "with open(r\"./representation_Facenet.pkl\",'rb') as f:\n",
    "    representations = pickle.load(f)\n",
    "print(len(representations))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('gpu_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2c813bd4616596c3c4efc4a100f4a14942e1729d75240bde9f2ced1484888dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
