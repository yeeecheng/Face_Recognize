{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "from retinaface import RetinaFace\n",
    "from deepface import DeepFace\n",
    "from deepface.basemodels import Facenet\n",
    "from deepface.commons import functions, realtime, distance as dst\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceRecognize:\n",
    "    \n",
    "    def __init__(self,model_name = \"Facenet\" , detector_backend = \"retinaface\" ,distance_metric =\"cosine\"):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.model = DeepFace.build_model(model_name)\n",
    "        self.detector_backend = detector_backend\n",
    "        self.distance_metric = distance_metric\n",
    "        self.detector = RetinaFace\n",
    "    \n",
    "    # detect face ,then label it \n",
    "    def detect(self,frame):\n",
    "\n",
    "        img = frame.copy()\n",
    "        face_detect_result  = self.detector.detect_faces(img)\n",
    "        \n",
    "        if len(face_detect_result) == 0 :\n",
    "            return frame , False\n",
    "        for face in face_detect_result:\n",
    "            ROI = face_detect_result[face]['facial_area'] #min_x , min_y , max_x ,max_y\n",
    "            cv2.rectangle(frame,(ROI[0],ROI[1]),(ROI[2],ROI[3]),(0,255,0),2)\n",
    "\n",
    "        return frame , True \n",
    "\n",
    "    # alignment \n",
    "    def processing_face(self,frame,target_size=(160,160)):\n",
    "\n",
    "        processed_img = self.detector.extract_faces(frame)\n",
    "        \n",
    "        if len(processed_img) != 1:\n",
    "            return None , False\n",
    "        \n",
    "        frame = cv2.resize(processed_img[0], target_size)\n",
    "\n",
    "        return frame , True\n",
    "\n",
    "    def normalized_img(self,img_path):\n",
    "\n",
    "        img  = cv2.imread(img_path)\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        img /= 255\n",
    "        # print(ii.shape)\n",
    "        img = functions.normalize_input(img = img , normalization='base')\n",
    "        return img \n",
    "\n",
    "    def represent(self , img_path):\n",
    "\n",
    "        img = self.normalized_img(img_path)  \n",
    "            \n",
    "        if \"keras\" in str(type(self.model)):\n",
    "            embedding =self.model.predict(img,verbose=0)[0].tolist()\n",
    "        else :\n",
    "            embedding = self.model.predict(img)[0].tolist()\n",
    "        \n",
    "        return embedding\n",
    "\n",
    "\n",
    "    def generate_representation(self , db_path):\n",
    "        \n",
    "        employees =  []\n",
    "        for r , d, f in os.walk(db_path):\n",
    "\n",
    "            for file in f:\n",
    "                \n",
    "                if ('.jpg' in file.lower()) or ('.png' in file.lower()):\n",
    "                    exact_path = r +\"/\" + file\n",
    "                    employees.append(exact_path)\n",
    "        \n",
    "        if len(employees) == 0 :\n",
    "            raise ValueError(\"There is no image !\")\n",
    "        \n",
    "        representations = []\n",
    "\n",
    "        progress_bar = tqdm(range(0,len(employees)),desc=\"Calculating\")\n",
    "\n",
    "        for index in progress_bar:\n",
    "\n",
    "            employee = employees[index]\n",
    "            instance = []\n",
    "            instance.append(employee)\n",
    "\n",
    "            representation = self.represent(employee)\n",
    "\n",
    "            instance.append(representation)\n",
    "\n",
    "            representations.append(instance)\n",
    "\n",
    "        shutil.rmtree(db_path)\n",
    "        return representations\n",
    "        \n",
    "\n",
    "    def generate_file(self,representations,has_file=False):\n",
    "        \n",
    "        file_name = \"representation_%s.pkl\" % (self.model_name)\n",
    "        if has_file:\n",
    "            with open(f\"./{file_name}\",'rb') as f :\n",
    "                org_representations = pickle.load(f)\n",
    "            \n",
    "            for i  in representations:\n",
    "                org_representations.append(i)\n",
    "\n",
    "            representations = org_representations\n",
    "\n",
    "        with open(f\"./{file_name}\",'wb') as f :\n",
    "            pickle.dump(representations,f)\n",
    "\n",
    "    def recognize(self,img_path):\n",
    "        \n",
    "        file_name = \"representation_%s.pkl\" % (self.model_name)\n",
    "\n",
    "        with open(f\"{file_name}\",'rb') as f:\n",
    "            representations = pickle.load(f)\n",
    "    \n",
    "        df = pd.DataFrame(representations , columns = [\"identity\",\"%s_representation\" % (self.model_name)])\n",
    "    \n",
    "        progress_bar = tqdm(range(0,1),desc=\"Analyzing\")\n",
    "\n",
    "        for i in progress_bar:\n",
    "            \n",
    "            target_representation = self.represent(img_path)\n",
    "\n",
    "\n",
    "            distances = []\n",
    "            for index ,instance in df.iterrows():\n",
    "                source_representation = instance[\"%s_representation\" % (self.model_name)]\n",
    "                \n",
    "                if self.distance_metric == \"cosine\":\n",
    "                    distance = dst.findCosineDistance(source_representation,target_representation)\n",
    "                elif self.distance_metric == \"euclidean\":\n",
    "                    distance = dst.findEuclideanDistance(source_representation,target_representation)\n",
    "                elif self.distance_metric == \"euclidean_12\":\n",
    "                    distance = dst.findEuclideanDistance(dst.l2_normalize(source_representation), dst.l2_normalize(target_representation))\n",
    "                \n",
    "                distances.append(distance)\n",
    "            \n",
    "            df[\"%s_%s\" % (self.model_name,self.distance_metric)] = distances\n",
    "            # find the accept range\n",
    "            threshold = dst.findThreshold(self.model_name,self.distance_metric)\n",
    "            # drop feature\n",
    "            df = df.drop(columns= [\"%s_representation\" % (self.model_name)])\n",
    "            # filter smaller and equal threshold\n",
    "            df = df[df[\"%s_%s\" % (self.model_name,self.distance_metric)] <= threshold]\n",
    "            # sort from small to large \n",
    "            df = df.sort_values(by = [\"%s_%s\" %(self.model_name,self.distance_metric)],ascending =True).reset_index(drop=True)\n",
    "            \n",
    "        \n",
    "        if len(df) == 0:\n",
    "            return \"Other\"\n",
    "        \n",
    "        else :\n",
    "            identity = df['identity'][0].split('/')[1].split('_')\n",
    "            return identity[0]+\" \"+identity[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_user(label):\n",
    "\n",
    "    \n",
    "    face_recognition = FaceRecognize()\n",
    "\n",
    "    # need num of user's data  \n",
    "    get_picture_num = 5\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        exit()\n",
    "\n",
    "    # create user dir \n",
    "    path = \"dataset\" \n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    with open(\"label.txt\",\"a+\") as f:\n",
    "        \n",
    "        f.write(\"user %s\\n\" %(label))\n",
    "\n",
    "    # cnt img_number \n",
    "    img_number = 0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        ret , frame  = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Cannot receive frame\")\n",
    "            break\n",
    "\n",
    "\n",
    "        # pre-processing the img to only face \n",
    "        frame , check = face_recognition.processing_face(frame)\n",
    "        # haven't detect face ,skip\n",
    "        if not check :\n",
    "            continue\n",
    "        \n",
    "        # show \n",
    "        cv2.imshow(\"frame\",frame)\n",
    "        if cv2.waitKey(100) & 0xff ==ord('q'):\n",
    "            break\n",
    "        \n",
    "        # save img \n",
    "        cv2.imwrite(f\"{path}/user_{label}_{img_number}.jpg\",frame)\n",
    "        img_number+=1\n",
    "        \n",
    "        if img_number >= get_picture_num:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    representations = face_recognition.generate_representation(path)\n",
    "\n",
    "    has_file = os.path.isfile(\"representation_Facenet.pkl\")\n",
    "    face_recognition.generate_file( representations ,has_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recognize_user():\n",
    "\n",
    "    face_recognize =FaceRecognize()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        exit()\n",
    "    while True :\n",
    "        \n",
    "        ret , frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Cannot receive frame\")\n",
    "            break\n",
    "        path = \"./9.png\"\n",
    "        frame = cv2.imread(path)\n",
    "        frame , check = face_recognize.processing_face(frame)\n",
    "        if not check:\n",
    "            print(\"There is no face\")\n",
    "            continue\n",
    "        \n",
    "        path = \"./detect.png\"\n",
    "        cv2.imwrite( path, frame)\n",
    "        \n",
    "        result = face_recognize.recognize(path)\n",
    "        print(\"detect %s\" % (result))\n",
    "        \n",
    "        if cv2.waitKey(100) & 0xff ==ord('q'):\n",
    "            break\n",
    "        \n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(MODE = \"Register\"):\n",
    "    \n",
    "    if MODE == \"Register\":\n",
    "        \n",
    "        register_user(\"2\")\n",
    "\n",
    "    elif MODE == \"Recognize\":\n",
    "        \n",
    "        recognize_user()\n",
    "main(\"Recognize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the representation size\n",
    "with open(r\"./representation_Facenet.pkl\",'rb') as f:\n",
    "    representations = pickle.load(f)\n",
    "print(len(representations))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('gpu_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2c813bd4616596c3c4efc4a100f4a14942e1729d75240bde9f2ced1484888dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
